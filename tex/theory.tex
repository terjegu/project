\chapter{Theory} % (fold)
\label{cha:theory}
The basic idea of the voice transformation is to make a linear prediction analysis of the signal and extract the estimate from the real signal to yield a source-filter separation. The filter coefficients can then be transformed to match the new voice, and the speech signal can be reestimate with the new filter coefficients as depicted in Figure~\ref{fig:VC}.
\begin{figure}[htbp]
  \centering
   \begin{tabular}[h]{c}
\xymatrix{ 
\mathbf{x} \ar[rr] & \ar[d]\ar[r] &*+<5mm>[F-,]{1-A(z)} \ar[rr]^{\mathbf{e}}& &*+<5mm>[F-,]{\frac{1}{1-\tilde{A}(z)}} \ar[r] & \mathbf{y}\\  % end line 1
  &*+<5mm>[F-,]{\txt{LPC}} \ar[rr]^<(0.25){A(z)} & \ar[u]&*+<5mm>[F-,]{\txt{FT}}\ar `[ru]^<(0.5){\tilde{A}(z)} [ur]&  &}
  \end{tabular}
  \caption{Filter transformation system}
  \label{fig:VC}
\end{figure}

The challenge in this procedure is to find the filter transformation function explained in Section~\ref{sec:conversion_function}. The system includes two parts, training and transformation. 
\begin{figure}[htbp]
	\centering
	\begin{tabular}[h]{c}
		\xymatrix{ 
\mathbf{x} \ar[r] &*+<5mm>[F-,]{\txt{LPC}}\ar[d]\ar @{=>}[r] &*+<5mm>[F-,]{\txt{GMM}}\ar `[rd]^{\boldsymbol{\Phi}} [dr] &\\ % end line 1
&*+<5mm>[F-,]{\txt{DTW}} \ar @<3pt>[rr]^<(0.15){\mathbf{x}} \ar @<-3pt>[rr]_<(0.15){\tilde{\mathbf{y}}} & &*+<5mm>[F-,]{\txt{Train TF}}\\ % end line 2
\mathbf{y} \ar[r] &*+<5mm>[F-,]{\txt{LPC}}\ar[u]&&}
	\end{tabular}
	\caption{Training of filter transformation parameters}
	\label{fig:VC_training}
\end{figure}
In the training process of the conversion function, depicted in Figure~\ref{fig:VC_training}, the two input signals, source $x$ and target $y$, first need to be aligned in time, Section~\ref{sec:dynamic_time_warping}. The source data is classified into probabilistic Gaussian mixture models (GMM), Section~\ref{sec:gaussian_mixture_model}, and used in a class-specific transform \cite{stylianou09}. The parameters in the transformation function are derived from a set of source vectors and corresponding time aligned target vectors, and the GMM fitted to the source.


\section{Gaussian Mixture Model} % (fold)
\label{sec:gaussian_mixture_model}
The GMM is a classical parametric model used in many pattern recognition techniques \cite{stylianou98}. Because of the wide variety of speech sound, representing all of them would require enormous complexity of both training data and the transformation function. A probabilistic Gaussian mixture models is a simpler and faster approach. GMM classifies a set of vectors into a smaller number of classes. Instead of representing the classes with their mean value, as VQ, GMM represents a class as a Gaussian distribution where the distributions can overlap. A GMM can represent the source with only a few parameters which there are well defined methods of estimating \cite{taletek}.

The GMM assumes that the probability distribution of the observed parameters takes the following parametric form
\begin{equation}
	\label{eq:gmm}
	p(\mathbf{x}) = \sum_{i=1}^{m} \alpha_i N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)
\end{equation}
where $m$ is the number of mixture models and $N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)$ denotes the p-dimensional normal distribution with the mean vector $\boldsymbol{\mu}_i$ and covariance matrix $\mathbf{\Sigma}_i$ defined by
\begin{equation}
	N(\mathbf{x}; \boldsymbol{\mu}, \mathbf{\Sigma}) = \frac{1}{\sqrt{(2\pi)^p\abs{\mathbf{\Sigma}}}} \exp\left[ -\frac{1}{2} (\mathbf{x} -\boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} -\boldsymbol{\mu})\right]
\end{equation}
and $\alpha_i$ in \eqref{eq:gmm} is the prior probability of class $i$ with constraints $\sum_{i=1}^{M}\alpha_i = 1$ and $\alpha_i \geq 0$. The input vectors, $\mathbf{x_i}$, are assumed to be independent \cite{stylianou98}.

The conditional probability that a given observation vector $\mathbf{x}$ belongs to the component $C_i$ of the GMM is given by Bayes' rule \cite{statistikk}
\begin{equation}
	\label{eq:bayes}
	P(C_i\vert \mathbf{x}) = \frac{\alpha_i N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)}{\sum_{j=1}^{m}\alpha_j N(\mathbf{x}; \boldsymbol{\mu}_j, \mathbf{\Sigma}_j)}
\end{equation}

The parameters $\boldsymbol{\alpha}, \boldsymbol{\mu}$ and $ \mathbf{\Sigma}$ can be estimated with the expectation maximisation (EM\abbrev{EM}{expectation maximisation}) algorithm. The EM algorithm is an iterative algorithm for unsupervised learning in which component information is unavailable. EM tries to find the parameters in the GMM that gives the maximum likelihood of the observed data $\mathbf{X}$. The initial values for the parameters of the GMM can be computed from the VQ representation of the source vectors. The next step is to find the expectation of the log-likelihood of the latent data given the current estimate of the parameters. A new estimate of the parameters is found by maximising the expected log-likelihood and the process is repeated until convergence \cite{taletek}.

% section Gaussian Mixture Model (end)

% 
% \section{Expectation Maximisation} % (fold)
% \label{sec:expectation_maximisation}
% 
% 
% We need to determine the parameter $\mathbf{\Phi} = \{\boldsymbol{\alpha}, \boldsymbol{\mu}, \mathbf{\Sigma}\}$ which maximises $P(Y=y\vert \mathbf{\Phi})$ where $y$ is the observed training data. We assume some parameter vector $\mathbf{\Phi}$ and estimate the probability of some unknown data $x$ occurred in the generation of $y$. We then compute a new $\bar{\mathbf{\Phi}}$ which is the maximum likelihood of $\mathbf{\Phi}$ and set the new $\bar{\mathbf{\Phi}}$ to be $\mathbf{\Phi}$ and repeat the process iteratively until the process converges \cite{taletek}. The process will converge if we choose $\bar{\mathbf{\Phi}}$ such that 
% \begin{equation}
% 	\label{eq:q_criteria}
% 	Q(\mathbf{\Phi},\bar{\mathbf{\Phi}})\geq Q(\mathbf{\Phi},\mathbf{\Phi})
% \end{equation}
% where 
% \begin{equation}
% 	\label{eq:q_function}
% 	Q(\mathbf{\Phi},\bar{\mathbf{\Phi}}) = E[\log P(X,Y=y\vert \bar{\mathbf{\Phi}})].
% \end{equation}
% % section Estimation Maximasation (end)

\section{Dynamic Time Warping} % (fold)
\label{sec:dynamic_time_warping}
Feature comparison of two signals gives more sense if they are aligned in time. If the signals are not aligned they will not appear as equal, if they are in fact equal but with a time shift. Dynamic time warping (DTW\abbrev{DTW}{dynamic time warping}) is an dynamic programming concept to warp two sequence such that the difference in the signals are minimised. The signals are segmented into small parts which are compared and given a similarity-score. For LP parameters a good similarity-score is the \emph{Itakura distance} \cite{itakura90},
\begin{equation}
	\label{eq:dtw_distance}
		d(\mathbf{a},\mathbf{b}) = \log\left(\frac{\mathbf{a}^T \mathbf{R}_s \mathbf{a}}{\mathbf{b}^T \mathbf{R}_s \mathbf{b}}\right)	
\end{equation}
where $\mathbf{a}$ is a column vector of LP coefficients of one segment from the source signal, $\mathbf{b}$ is a column vector of LP coefficients of one segments from the target vector and $\mathbf{R}_s$ is the autocorrelation matrix of the source signal. The numerator of \eqref{eq:dtw_distance} is the residual, or the energy of the error, from the LP analysis of the source signal with the source coefficients $\mathbf{a}$ whilst the denominator is the residual from the LP analysis of the \emph{source} signal with the \emph{target} coefficients $\mathbf{b}$. 

The minimum distance between the two signals can be found by solving the recursion \cite{taletek}
\begin{equation}
	\label{eq:dtw_recursion}
	\begin{split}
		D(i,j) = \min \bigl[&D(i-1,j-1)+\alpha d(\mathbf{A}_i,\mathbf{B}_j),\\
		& D(i-1,j)+\beta d(\mathbf{A}_i,\mathbf{B}_j),\\
		& D(i,j-1)+\beta d(\mathbf{A}_i,\mathbf{B}_j),\\
		& D(i-2,j-1)+\gamma d(\mathbf{A}_i,\mathbf{B}_j),\\
		& D(i-1,j-2)+\gamma d(\mathbf{A}_i,\mathbf{B}_j)\bigr]		
	\end{split}
\end{equation}
where $\mathbf{A}_i$ and $\mathbf{B}_i$ denotes the LP coefficients of segment $i$ from the two signals. 
% I.e. the shortest path from $A$ to $C$ is the shortest path from $A$ to $B$ plus the shortest path from $B$ to $C$. 
The problem is broken down into simpler subproblems, hence dynamic programming. 

The possible paths are shown in Figure~\ref{fig:dtw_shortest_path}. 
\begin{figure}[htbp]
	\begin{center}
		\setlength{\unitlength}{0.8cm}
		\begin{picture}(8,8)(0,0)
		\put(0,0){\vector(1,0){8}}
		\put(7,-0.5){$\mathbf{A}$}
		\put(-0.5,7){$\mathbf{B}$}
		\put(0,0){\vector(0,1){8}}
		\put(7,7){\circle*{0.3}}
		\put(4,4){\vector(1,1){2.8}}
		\put(4,7){\vector(1,0){2.8}}
		\put(7,4){\vector(0,1){2.8}}
		\put(1,4){\vector(2,1){5.8}}
		\put(4,1){\vector(1,2){2.9}}
		\put(5,4){$\gamma$}
		\put(3.7,5.7){$\gamma$}
		\put(7.1,5){$\beta$}
		\put(5,7.1){$\beta$}
		\put(5,5.4){$\alpha$}
		\put(2.6,7){\tiny{$(i-1,j)$}}
		\put(6.6,3.7){\tiny{$(i,j-1)$}}
		\put(0.1,3.7){\tiny{$(i-2,j-1)$}}
		\put(3.1,0.7){\tiny{$(i-1,j-2)$}}
		\put(3,3.7){\tiny{$(i-1,j-1)$}}
		\end{picture}
		\caption{DTW shortest path calculations}
		\label{fig:dtw_shortest_path}
	\end{center}
\end{figure}
The weights $\alpha,\beta$ and $\gamma$, called local constraints, are optional and could have a significant effect on the outcome. For instance, the $\beta$ weights can be assigned a larger value to avoid multiple skipping or repetition of frames. Global constraints can be applied in addition to the local constraints which limits the resulting path by borders to guarantee a maximum modification of the signals.

The resulting shortest path is used to duplicate and/or delete frames in the target to get a time-aligned version of the target vector of the same length as the source vector.
% section Dynamic Time Warping (end)


\section{Filter Transformation} % (fold)
\label{sec:conversion_function}
The process of filter transformation consist of altering the filter coefficients of the source speaker to match a target speakers coefficients. Given a set of time-aligned source and target vectors, we want to define a transformation function which yields the most likely target vector given a new source vector
\begin{equation}
	\mathcal{F}(\mathbf{x}) = E[\mathbf{y}\vert \mathbf{x}]
\end{equation}
If we assume that the source and target vectors are jointly Gaussian the likelihood of $\mathbf{y}$ given $\mathbf{x}$ for a single component GMM can be expressed as \cite{kay93}
\begin{equation}
	E[\mathbf{y}\vert \mathbf{x}] = \boldsymbol{\mu}^y + \mathbf{\Sigma}^{yx} \mathbf{\Sigma}^{xx^{-1}} (\mathbf{x}-\boldsymbol{\mu}^x)
\end{equation}
where $E$ denotes the expectation, $\boldsymbol{\mu}$ is the mean
\begin{equation}
	\boldsymbol{\mu}^y = E[\mathbf{y}]
\end{equation}
and $\mathbf{\Sigma}$ is the cross-covariance matrix
\begin{equation}
	\mathbf{\Sigma}^{yx} = E[(\mathbf{y}-\boldsymbol{\mu}^y)(\mathbf{x}-\boldsymbol{\mu}^x)^T]
\end{equation}

Stylianou \etal \cite{stylianou95} suggested using this formula for a multicomponent GMM yielding the transformation function
\begin{equation}
	\label{eq:conversion_function}
	\begin{split}
		\mathcal{F}(\mathbf{x}_t) =& E[\mathbf{y}\vert \mathbf{x}_t]\\
		=& \sum_{i=1}^{m}P(C_i \vert \mathbf{x}_t)[\boldsymbol{\mu}_i^y + \mathbf{\Sigma}_i^{yx} \mathbf{\Sigma}_i^{xx^{-1}} (\mathbf{x}_t-\boldsymbol{\mu}_i^x)]
	\end{split}
\end{equation}
where the likelihoods are weighted with the conditional probabilities of $\mathbf{x}$ belonging to component $C$. Note that \eqref{eq:conversion_function} is not dependent of the target vector $\mathbf{y}$.

The mean and covariance of the source vector $\mathbf{x}$ are derived from the GMM but the mean of the target vectors $\boldsymbol{\mu}^y$ and cross-covariance matrix $\mathbf{\Sigma}^{yx}$ are unknown and need to be estimated such as the total squared conversion error $\epsilon$ is minimised
\begin{equation}
	\label{eq:conversion_error}
	\epsilon = \sum_{t} \norm{\mathbf{y}_t - \mathcal{F}(\mathbf{x}_t)}^2
\end{equation}

This can be achieved by reformulating equation \eqref{eq:conversion_function} into a single matrix equation
\begin{equation}
	\label{eq:least_square_problem}
	\begin{split}
		\mathbf{Y} = &\mathbf{P}\boldsymbol{\mu^y} + \mathbf{D}\mathbf{\Sigma}^{yx} \\
		= & \begin{bmatrix}
			\mathbf{P}& \vdots &\mathbf{D}
		\end{bmatrix}
		\begin{bmatrix}
			\boldsymbol{\mu^y} \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
	\end{split}
\end{equation}
where $\mathbf{Y}$ is the training set of the target spectral vectors with dimensions $n\times p$ and $\mathbf{P}$ is a $n \times m$ matrix with the posterior probabilities
\begin{equation}
	\label{eq:P_matrix}
	\mathbf{P} = \begin{bmatrix}
		P(C_1\vert \mathbf{x}_1) & \dots & P(C_m\vert \mathbf{x}_1) \\
		P(C_1\vert \mathbf{x}_2) & \dots & P(C_m\vert \mathbf{x}_2) \\
		\vdots & & \vdots \\
		P(C_1\vert \mathbf{x}_n) & \dots & P(C_m\vert \mathbf{x}_n) \\
	\end{bmatrix}
\end{equation}
$\mathbf{D}$ is a $n \times pm$ matrix defined as
\begin{equation}
	\label{eq:D_matrix}
	\mathbf{D} = \begin{bmatrix}
		P(C_1\vert \mathbf{x}_1)(\mathbf{x}_1 - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_1)(\mathbf{x}_1 - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
		P(C_1\vert \mathbf{x}_2)(\mathbf{x}_2 - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_2)(\mathbf{x}_2 - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
		\vdots & & \vdots \\
		P(C_1\vert \mathbf{x}_n)(\mathbf{x}_n - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_n)(\mathbf{x}_n - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
	\end{bmatrix}
\end{equation}

The two unknown matrices $\boldsymbol{\mu}^y$ and $\mathbf{\Sigma}^{yx}$ will have dimensions $m\times p$ and $m \times (p\times p)$ 
\begin{equation}
	\label{eq:v_matrix}
	\boldsymbol{\mu}^y = 
	\begin{bmatrix}
		\boldsymbol{\mu}^y_1 \vdots \boldsymbol{\mu}^y_2 \vdots \dots \vdots \boldsymbol{\mu}^y_m
	\end{bmatrix}^T
\end{equation}
\begin{equation}
	\label{gamma_matrix}
	\mathbf{\Sigma}^{yx} = 
	\begin{bmatrix}
		\mathbf{\Sigma}_1^{yx} \vdots \mathbf{\Sigma}_2^{yx} \vdots \dots \vdots \mathbf{\Sigma}_m^{yx}
	\end{bmatrix}^T
\end{equation}

Equation \eqref{eq:least_square_problem} is a least-square problem which can be solved by the normal equations \cite{lawson74}
\begin{equation}
	\label{eq:param_computed}
	\begin{split}
		\left( 
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\begin{bmatrix}
			\mathbf{P} & \vdots & \mathbf{D}
		\end{bmatrix}
		 \right)
		\begin{bmatrix}
			\boldsymbol{\mu}^y \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
		= &
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\mathbf{Y} \\ % end line 1
		\begin{bmatrix}
			\boldsymbol{\mu}^y \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
		= &
		\left( 
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\begin{bmatrix}
			\mathbf{P} & \vdots & \mathbf{D}
		\end{bmatrix}
		 \right)^{-1}
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\mathbf{Y} \\ % end line 2
	\end{split}
\end{equation}
% section Conversion Function (end)


% \section{Source Mapping} % (fold)
% \label{sec:source_mapping}
% LANGT FRA FERDIG
% 
% Source mapping intends to change to prosody of the source speaker to match a target speaker. The goal is to alter the pitch and duration of the signal without affecting the spectral characteristics. 
% 
% If the source is voiced it can be represented as a function of pitch cycles
% \begin{equation}
% 	x(n)=\sum_{i=-\infty}^{\infty}x_i(n-t_x(i))
% \end{equation}
% where the pitch period in samples at $t_s(i)$ is
% \begin{equation}
% 	P_x(i)=t_x(i)-t_x(i-1)
% \end{equation}
% 
% One pitch cycle can be represented by applying a Hamming window, $w$, of length two pitch periods to the signal. The term ``overlap and add'' comes from the use of overlapping windowed segments.
% \begin{equation}
% 	x_i(n)=w_i(n)x(n)
% \end{equation}
% If we replace the source timing instances, $t_x$, with the ones from the target, $t_y$, and replacing the pitch cycles $x$ with the target $y$ we get the desired prosody \cite{taletek}.
% \begin{equation}
% 	y(n)=\sum_{j=-\infty}^{\infty}x_j(n-t_y(j)) % should have been y_j
% \end{equation}
% 
% The target pitch cycles, $y$, can be obtained by mapping the closest corresponding pitch cycles from $x$ by \eg DTW. The presented method will work for unvoiced speech as well if the spacing is smaller than 10 ms \cite{taletek}. 
% \cite{moulines95}
% % section Source Mapping (end)

\section{Signal Representation} % (fold)
\label{sec:signal_representation}
The signal representation used in the source-filter seperation is linear prediction coefficients, derived by coding (LPC\abbrev{LPC}{linear predictive coding}). While the LP representation is a delicate representations of speech signals, it is not the best choice when it comes to manipulating the parameters in the filter transformation procedure, because they are not necessarily stable. A number of equivalent representations can be used instead for this purpose such as line spectrum frequencies (LSF\abbrev{LSF}{line spectrum frequencies}) \cite{taletek}.

\subsection{Linear Predictive Coding} % (fold)
\label{sub:lpc}
LPC approximates the signal as a $p$-th order all-pole filter by predicting the current sample as a linear combination of its last $p$ samples \cite{digsig}
\begin{equation}
	\tilde{x}[n] = \sum_{k=1}^{p}a_k x[n-k]
\end{equation}
The prediction error by this representation is 
\begin{equation}
	\begin{split}
		e[n]= & x[n]-\tilde{x}[n]\\
		= & x[n]-\sum_{k=1}^{p}a_k x[n-k]
	\end{split}
\end{equation}

The prediction coefficients, $a_k$, can be estimated by the minimum mean square error technique which estimates the coefficients that minimise the total prediction error $E$.
\begin{equation}
	\label{eq:prediction_error}
	\begin{split}
		E = & \sum_{n}e^2[n]\\
		= & \sum_{n}\left( x[n]-\sum_{k=1}^{p}a_k x[n-k] \right)^2
	\end{split}
\end{equation}
The coefficients can be obtained by taking the derivative of \eqref{eq:prediction_error} with respect to $a_i$ and equating to 0. This yields a set of $p$ linear equations with $p$ unknown parameters which easily can be solved \cite{digsig}. The resulting $a_k$ coefficients are the linear prediction coefficients which represents the signal.
% subsection Linear Predictive Coding (end)

\subsection{Line Spectral Frequencies} % (fold)
\label{sub:line_spectral_frequencies}
LSF is an equivalent representation of LPC which easily can be controlled for stability. It can be converted from the LP coefficients $A(z)$ and back again. It is derived from the roots of the polynomials $P(z)$ and $Q(z)$ 
\begin{equation}
	\label{eq:p_z}
	P(z) = A(z)+z^{-(p+1)}A(z^{-1})
\end{equation}
\begin{equation}
	\label{eq:q_z}
	Q(z) = A(z)-z^{-(p+1)}A(z^{-1})
\end{equation}
The zeros of $P(z)$ and $Q(z)$ are respectively symmetric and anti-symmetric. When $A(z)$ is minimum phase the zeros of $P(z)$ and $Q(z)$ are all on the unit circle and the polynomials can thus be written in product for of
$1-z^{-1}\exp(-j\omega_k)$, where $\omega_k$ is the LSF frequencies. The derivation of the first LSF coefficients is shown in \cite[p. 304]{taletek}.

\begin{figure}[htbp]
	\centering
	\begin{tabular}[h]{c}
		\xymatrix{ 
		A(z) \ar[r] &*+<5mm>[F-,]{ LPC\rightarrow LSF} \ar[r] &*+<5mm>[F-,]{	\txt{FM}}\ar[r] &*+<5mm>[F-,]{LSF\rightarrow LPC} \ar[r] & \hat{A}(z)}    
	\end{tabular}
	\caption{LPC to LSF conversion used in filter transformation}
	\label{fig:lpc_to_lsf}
\end{figure}
LSF is used in the transformation function, as depicted in Figure~\ref{fig:lpc_to_lsf}, to guarantee stability.

% subsection Line Spectral Frequencies (end)
% section Signal Representation (end)

% \subsection{Mel-Frequency Cepstrum} % (fold)
% \label{sub:mel_frequency_cepstrum}
% In the dynamic time warping algorithm presented in Section~\ref{sec:dynamic_time_warping} MFC coefficients are used instead of LP coefficients because they have the feature of Euclidean measures.
% 
% The cepstrum of a signal is a homomorphic transformation to the \emph{quefrency} domain \cite{taletek}. The Mel-frequency cepstrum is a real cepstrum with a nonlinear frequency scale which approximates the behaviour of the human auditory system. The process of computing the MFC coefficents are depicted in Figure~\ref{fig:mfcc}.
% 
% The Mel-scale is defined as \cite{taletek}
% \begin{equation}
% 	B(f) = 1125\ln(1+f/700).
% \end{equation}
%  \begin{figure}[htbp]
%   \centering
%   \begin{tabular}[h]{c}
% \xymatrix{ 
%   x[n] \ar[r] &*+<5mm>[F]{\text{DFT}}\ar[r] &*+<5mm>[F]{\abs{\cdot}^2}\ar[r] &*+<5mm>[F]{\text{MEL}} \ar[r] &*+<5mm>[F]{\log(\cdot)} \ar[r] &*+<5mm>[F]{\text{DCT}} \ar[r] & c[n]}    
%   \end{tabular}
%   \caption{Computation of Mel-frequency cepstrum coefficients}
%   \label{fig:mfcc}
% \end{figure}
% 
% % subsection Mel-Frequency Cepstrum (end)
% chapter Theory (end)