\chapter{Theory} % (fold)
\label{cha:theory}
\begin{figure}[htbp]
  \centering
   \begin{tabular}[h]{c}
\xymatrix{ 
x[n] \ar[r] &*+<5mm>[F-,]{\txt{Buffer}} \ar[d]\ar[r] &*+<5mm>[F-,]{1-A(z)}\ar[rr]^{e[n]}& &*+<5mm>[F-,]{\frac{1}{1-\tilde{A}(z)}} \ar[r] & y[n]\\
  &*+<5mm>[F-,]{\txt{LPC}} \ar[rr]^<(0.25){A(z)} & \ar[u]&*+<5mm>[F-,]{\txt{VC}}\ar `[ru]^<(0.5){\tilde{A}(z)} [ur]&  &}
  \end{tabular}
  \caption{Voice Conversion}
  \label{fig:VC}
\end{figure}

The basic idea of the voice conversion is to make a LP analysis of the signal, extract the estimate from the real signal, adapt the coefficients to the new voice and reestimate the signal with the new coefficients as depicted in Figure~\ref{fig:VC}.

The system includes two parts, training and transformation. The challenge in this procedure is the find the conversion function explained in Section~\ref{sec:conversion_function}. In the training process of the conversion function, depicted in Figure~\ref{fig:VC_training}, the two input signals, source $x$ and target $y$, first need to be time aligned by dynamic time warping, Section~\ref{sec:dynamic_time_warping}. Because of the wide variety of speech sound, a single global transform is not sufficient to capture all the different sounds. Instead we could classify the speech sound into probabilistic gaussian mixture models (GMM), Section~\ref{sec:gaussian_mixture_model}, and apply a class-specific transform \cite{stylianou09}. The GMM parameters are used in training of the conversion function explained in Section~\ref{sec:conversion_function}.
\begin{figure}[htbp]
	\centering
	\begin{tabular}[h]{c}
		\xymatrix{ 
x[n] \ar[r] &*+<5mm>[F-,]{\txt{LPC}}\ar[d] &*+<5mm>[F-,]{\txt{GMM}}\ar `[rd]^{\boldsymbol{\Phi}} [dr] &\\ % end line 1
&*+<5mm>[F-,]{\txt{DTW}} \ar @<3pt>[rr]^<(0.15){\tilde{x}[n]} \ar @<-3pt>[rr]_<(0.15){y[n]} & \ar[u] &*+<5mm>[F-,]{\txt{Train VC}}\\ % end line 2
y[n] \ar[r] &*+<5mm>[F-,]{\txt{LPC}}\ar[u]&&}
	\end{tabular}
	\caption{Training of Voice Conversion Parameters}
	\label{fig:VC_training}
\end{figure}


\section{Conversion Function} % (fold)
\label{sec:conversion_function}
The available data for the conversion function is time-aligned source and target vectors, Section~\ref{sec:dynamic_time_warping}, which are of the same length $n$ and the pre-trained gaussian mixture models. A conversion function suggested by Yannis Stylianou \cite{stylianou95} is used in this paper:
\begin{defn}
	\label{defn:conversion_function}
	\begin{equation}
		\label{eq:conversion_function}
		\begin{split}
		\mathcal{F}(\mathbf{x}_t) =& E[\mathbf{y}\vert \mathbf{x}_t]\\
		 =& \sum_{i=1}^{m}P(C_i \vert \mathbf{x}_t)[\boldsymbol{\mu}_i^y + \mathbf{\Sigma}_i^{yx} \mathbf{\Sigma}_i^{xx^{-1}} (\mathbf{x}_t-\boldsymbol{\mu}_i^x)]
		\end{split}
	\end{equation}	
\end{defn}
The conversion function is a weighted sum of minimum mean square error (MMSE\abbrev{MMSE}{minimum mean square error}) estimate of the target vector $\mathbf{y}_t$ given the observed value of $\mathbf{x}_t$, which are jointly Gaussian \cite{stylianou98}. The MMSE is given by \cite{taletek}
\begin{equation}
	\label{eq:mmse}
	E[\mathbf{y}\vert \mathbf{x}=\mathbf{x}_t] = \boldsymbol{\mu}^y + \mathbf{\Sigma}^{yx} \mathbf{\Sigma}^{xx^{-1}} (\mathbf{x}_t-\boldsymbol{\mu}^x)
\end{equation}
where $E$ denotes the expectation, $\boldsymbol{\mu}$ is the mean
\begin{equation}
	\boldsymbol{\mu}^y = E[\mathbf{y}]
\end{equation}
and $\mathbf{\Sigma}$ is the cross-covariance matrix
\begin{equation}
	\mathbf{\Sigma}^{yx} = E[(\mathbf{y}-\boldsymbol{\mu}^y)(\mathbf{x}-\boldsymbol{\mu}^x)^T].
\end{equation}

If the gaussian components of the mixture could be separated, the conversion function $\mathcal{F}()$ is modifying the posterior mean and covariance of each component. Since this is not the case in practice the term is weighted by the conditional probability that the observed data $\mathbf{x}_t$ belongs to the component $C_i$.

The variables $\boldsymbol{\mu}^y$ and $\mathbf{\Sigma}^{yx}$ are unknown and need to be estimated such as the squared conversion error is minimised
\begin{equation}
	\label{eq:conversion_error}
	\epsilon_{MSE}=E \biggl[ \norm{\mathbf{y} - \mathcal{F}(\mathbf{x})}^2\biggr].
\end{equation}

The optimal values of the parameters can be computed by solving the following set of normal equations \cite{stylianou95}:
\begin{equation}
	\begin{split}
		\mathbf{y} = &\mathbf{P}\boldsymbol{\mu^y} + \mathbf{D}\mathbf{\Sigma}^{yx} \\
		= & \begin{bmatrix}
			\mathbf{P}& \vdots &\mathbf{D}
		\end{bmatrix}
		\begin{bmatrix}
			\boldsymbol{\mu^y} \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
	\end{split}
\end{equation}
\begin{equation}
	\label{eq:param_computed}
	\begin{split}
		\left( 
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\begin{bmatrix}
			\mathbf{P} & \vdots & \mathbf{D}
		\end{bmatrix}
		 \right)
		\begin{bmatrix}
			\boldsymbol{\mu}^y \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
		= &
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\mathbf{y} \\ % end line 1
		\begin{bmatrix}
			\boldsymbol{\mu}^y \\
			\dots \\
			\mathbf{\Sigma}^{yx}
		\end{bmatrix}
		= &
		\left( 
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\begin{bmatrix}
			\mathbf{P} & \vdots & \mathbf{D}
		\end{bmatrix}
		 \right)^{-1}
		\begin{bmatrix}
			\mathbf{P}^T \\
			\dots \\
			\mathbf{D}^T
		\end{bmatrix}
		\mathbf{y} \\ % end line 2
	\end{split}
\end{equation}
where $\mathbf{y}$ is the target spectral vectors and $\mathbf{P}$ is a $n \times m$ matrix with the conditional probabilities
\begin{equation}
	\label{eq:P_matrix}
	\mathbf{P} = \begin{bmatrix}
		P(C_1\vert \mathbf{x}_1) & \dots & P(C_m\vert \mathbf{x}_1) \\
		P(C_1\vert \mathbf{x}_2) & \dots & P(C_m\vert \mathbf{x}_2) \\
		\vdots & & \vdots \\
		P(C_1\vert \mathbf{x}_n) & \dots & P(C_m\vert \mathbf{x}_n) \\
	\end{bmatrix}.
\end{equation}
$\mathbf{D}$ is a $n \times pm$ matrix defined as
\begin{equation}
	\label{eq:D_matrix}
	\mathbf{D} = \begin{bmatrix}
		P(C_1\vert \mathbf{x}_1)(\mathbf{x}_1 - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_1)(\mathbf{x}_1 - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
		P(C_1\vert \mathbf{x}_2)(\mathbf{x}_2 - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_2)(\mathbf{x}_2 - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
		\vdots & & \vdots \\
		P(C_1\vert \mathbf{x}_n)(\mathbf{x}_n - \boldsymbol{\mu}_1^x)^T\mathbf{\Sigma}_1^{xx^{-1}} & \dots & P(C_m\vert \mathbf{x}_n)(\mathbf{x}_n - \boldsymbol{\mu}_m^x)^T\mathbf{\Sigma}_m^{xx^{-1}} \\
	\end{bmatrix}.
\end{equation}
The two unknown matrices $\boldsymbol{\mu}^x$ and $\mathbf{\Sigma}^{xx}$ will have dimensions $m\times p$ and $m \times (p\times p)$ 
\begin{equation}
	\label{eq:v_matrix}
	\boldsymbol{\mu}^x = 
	\begin{bmatrix}
		\boldsymbol{\mu}^x_1 \vdots \boldsymbol{\mu}^x_2 \vdots \dots \vdots \boldsymbol{\mu}^x_m
	\end{bmatrix}^T
\end{equation}
\begin{equation}
	\label{gamma_matrix}
	\mathbf{\Sigma}^{xx} = 
	\begin{bmatrix}
		\mathbf{\Sigma}_1^{xx} \vdots \mathbf{\Sigma}_2^{xx} \vdots \dots \vdots \mathbf{\Sigma}_m^{xx}
	\end{bmatrix}^T.
\end{equation}
% section Conversion Function (end)

\section{Dynamic Time Warping} % (fold)
\label{sec:dynamic_time_warping}
One way to time align two signals is to utilise dynamic time warping (DTW\abbrev{DTW}{dynamic time warping}). DTW is an dynamic programming concept to warp two sequence such as the difference in the signals are minimised. If we window the signal into small segments of \eg 20 ms we can make a LP analysis of the segments and use Itakura distance $d$ as a difference metric \cite{itakura90}.
\begin{equation}
	\label{eq:dtw_distance}
		d(\mathbf{a},\mathbf{b}) = \log\frac{\mathbf{a}^T \mathbf{R}_s \mathbf{a}}{\mathbf{b}^T \mathbf{R}_s \mathbf{b}}
\end{equation}
where $\mathbf{a}$ is the LP coefficients of one segment from the source signal, $\mathbf{b}$ is the LP coefficients of one segments from the target vector and $\mathbf{R}_s$ is the autocorrelation matrix of the source signal. The nominator of \eqref{eq:dtw_distance} is the residual, or the energy of the error, from the LP of the source signal with the source coefficients $\mathbf{a}$ whilst the denominator is the residual from the LP of the \emph{source} signal with the \emph{target} coefficients $\mathbf{b}$. 

The minimum distance between the two signals can be found by solving the recursion \cite{taletek}
\begin{equation}
	\label{eq:recursion}
	D(i,j) = \min_k\left[D(i-1,k)+d(\mathbf{A}_k,\mathbf{B}_j)\right]
\end{equation}
where $\mathbf{A}_k$ denotes the LP coefficients of segment $k$.
I.e. the shortest path from $A$ to $C$ is the shortest path from $A$ to $B$ plus the shortest path from $B$ to $C$. The problem is broken down into simpler subproblems, hence dynamic programming.
% section Dynamic Time Warping (end)

\section{Gaussian Mixture Model} % (fold)
\label{sec:gaussian_mixture_model}
The GMM is a classical parametric model used in many pattern recognition techniques \cite{stylianou98}. The GMM assumes that the probability distribution of the observed parameters takes the following parametric form
\begin{equation}
	\label{eq:gmm}
	p(\mathbf{x}) = \sum_{i=1}^{m} \alpha_i N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)
\end{equation}
where $m$ is the number of mixture models and $N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)$ denotes the p-dimensional normal distribution with the mean vector $\boldsymbol{\mu}_i$ and covariance matrix $\mathbf{\Sigma}_i$ defined by
\begin{equation}
	N(\mathbf{x}; \boldsymbol{\mu}, \mathbf{\Sigma}) = \frac{1}{\sqrt{(2\pi)^p\abs{\mathbf{\Sigma}}}} \exp\left[ -\frac{1}{2} (\mathbf{x} -\boldsymbol{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} -\boldsymbol{\mu})\right]
\end{equation}
and the $\alpha_i$ in \eqref{eq:gmm} is a normalised positive scalar; $\sum_{i=1}^{M}\alpha_i = 1$ and $\alpha_i \geq 0$. The input vectors, $\mathbf{x_i}$, are assumed to be independent.

In the GMM, each component is described by its center, $\boldsymbol{\mu}_i$, and the spreading around the center of the component, $\mathbf{\Sigma_i}$. The frequency of each component in the observation is represented by mixture weights, $\alpha_i$ \cite{stylianou98}. The conditional probability that a given observation vector $\mathbf{x}$ belongs to the component $C_i$ of the GMM is given by Bayes' rule \cite{statistikk} as
\begin{equation}
	\label{eq:bayes}
	P(C_i\vert \mathbf{x}) = \frac{\alpha_i N(\mathbf{x}; \boldsymbol{\mu}_i, \mathbf{\Sigma}_i)}{\sum_{j=1}^{m}\alpha_j N(\mathbf{x}; \boldsymbol{\mu}_j, \mathbf{\Sigma}_j)}.
\end{equation}

The parameters $\boldsymbol{\alpha}, \boldsymbol{\mu}$ and $ \mathbf{\Sigma}$ can be estimated with the expectation maximisation algorithm, Section~\ref{sec:expectation_maximisation}.

% section Gaussian Mixture Model (end)

\section{Expectation Maximisation} % (fold)
\label{sec:expectation_maximisation}
The expectation maximisation, EM \abbrev{EM}{expectation maximisation}, algorithm is an iterative algorithm for unsupervised learning in which component information is unavailable or only partly available \cite{taletek}. It estimates the model parameters by maximising the log-likelihood of incomplete data and maximising the expectation of log-likelihood from complete data.

We need to determine the parameter $\mathbf{\Phi} = \{\boldsymbol{\alpha}, \boldsymbol{\mu}, \mathbf{\Sigma}\}$ which maximises $P(Y=y\vert \mathbf{\Phi})$ where $y$ is the observed training data. We assume some parameter vector $\mathbf{\Phi}$ end estimate the probability of some unknown data $x$ occurred in the generation of $y$. We then compute a new $\bar{\mathbf{\Phi}}$ which is the maximum likelihood of $\mathbf{\Phi}$ and set the new $\bar{\mathbf{\Phi}}$ to be $\mathbf{\Phi}$ and repeat the process iteratively until the process converges \cite{taletek}. The process will converge if we choose $\bar{\mathbf{\Phi}}$ such that 
\begin{equation}
	\label{eq:q_criteria}
	Q(\mathbf{\Phi},\bar{\mathbf{\Phi}})\geq Q(\mathbf{\Phi},\mathbf{\Phi})
\end{equation}
where 
\begin{equation}
	\label{eq:q_function}
	Q(\mathbf{\Phi},\bar{\mathbf{\Phi}}) = E[\log P(X,Y=y\vert \bar{\mathbf{\Phi}})].
\end{equation}
% section Estimation Maximasation (end)

\section{Signal Representation} % (fold)
\label{sec:signal_representation}
\subsection{Linear Predictive Coding} % (fold)
\label{sub:lpc}
The main signal representation of choice is linear predictive coding (LPC\abbrev{LPC}{linear predictive coding}) also known as auto-regressive(AR\abbrev{AR}{auto-regressive}) modelling. 

LPC approximates the signal as an all-pole filter with a sufficient number of poles, \eg $p=16$, by predicting the current sample as a linear combination of its last $p$ samples \cite{digsig}
\begin{equation}
	\tilde{x}[n] = \sum_{k=1}^{p}a_k x[n-k].
\end{equation}
The prediction error by this representation is 
\begin{equation}
	\begin{split}
		e[n]= & x[n]-\tilde{x}[n]\\
		= & x[n]-\sum_{k=1}^{p}a_k x[n-k].
	\end{split}
\end{equation}

The predictor coefficients, $a_k$, can be estimated by the minimum mean square technique which chooses the coefficients that minimise the total prediction error $E$.
\begin{equation}
	\label{eq:prediction_error}
	\begin{split}
		E = & \sum_{n}e^2[n]\\
		= & \sum_{n}\left( x[n]-\sum_{k=1}^{p}a_k x[n-k] \right)^2
	\end{split}
\end{equation}
This can be obtained by taking the derivative of \eqref{eq:prediction_error} with respect to $a_i$ and equating to $0$. This yields a set of $p$ linear equations with $p$ unknown parameters \cite{digsig} which easily can be solved.
% subsection Linear Predictive Coding (end)

\subsection{Line Spectral Frequencies} % (fold)
\label{sub:line_spectral_frequencies}
While the LPC representation is a delicate representations of speech signals, it is not the best choice when it comes to manipulating the parameters in the voice conversion because they are not necessarily stable. A number of equivalent representations can be used instead for this purpose such as line spectrum frequencies (LSF\abbrev{LSF}{line spectrum frequencies}) \cite{taletek}.

LSF is an equivalent representation of LPC witch can be directly derived from the LP coefficients $A(z)$ and back again. It is derived from the roots of the polynomials $P(z)$ and $Q(z)$ 
\begin{equation}
	\label{eq:p_z}
	P(z) = A(z)+z^{-(p+1)}A(z^{-1})
\end{equation}
\begin{equation}
	\label{eq:q_z}
	Q(z) = A(z)-z^{-(p+1)}A(z^{-1}).
\end{equation}
The derivation of the first LSF coefficients are shown in \cite[p. 304]{taletek}.

In the voice conversion we can therefor transform the LP coefficients to LSF coefficients before the adaption and back agin before the re-estimation of the signal depicted in Figure~\ref{fig:lpc_to_lsf}.
\begin{figure}[htbp]
	\centering
	\begin{tabular}[h]{c}
		\xymatrix{ 
		A(z) \ar[r] &*+<5mm>[F-,]{ LPC\rightarrow LSF} \ar[r] &*+<5mm>[F-,]{	VC}\ar[r] &*+<5mm>[F-,]{LSF\rightarrow LPC} \ar[r] & \hat{A}(z)}    
	\end{tabular}
	\caption{LPC to LSF transformation in the voice conversion}
	\label{fig:lpc_to_lsf}
\end{figure}
% subsection Line Spectral Frequencies (end)
% section Signal Representation (end)

% \subsection{Mel-Frequency Cepstrum} % (fold)
% \label{sub:mel_frequency_cepstrum}
% In the dynamic time warping algorithm presented in Section~\ref{sec:dynamic_time_warping} MFC coefficients are used instead of LP coefficients because they have the feature of Euclidean measures.
% 
% The cepstrum of a signal is a homomorphic transformation to the \emph{quefrency} domain \cite{taletek}. The Mel-frequency cepstrum is a real cepstrum with a nonlinear frequency scale which approximates the behaviour of the human auditory system. The process of computing the MFC coefficents are depicted in Figure~\ref{fig:mfcc}.
% 
% The Mel-scale is defined as \cite{taletek}
% \begin{equation}
% 	B(f) = 1125\ln(1+f/700).
% \end{equation}
%  \begin{figure}[htbp]
%   \centering
%   \begin{tabular}[h]{c}
% \xymatrix{ 
%   x[n] \ar[r] &*+<5mm>[F]{\text{DFT}}\ar[r] &*+<5mm>[F]{\abs{\cdot}^2}\ar[r] &*+<5mm>[F]{\text{MEL}} \ar[r] &*+<5mm>[F]{\log(\cdot)} \ar[r] &*+<5mm>[F]{\text{DCT}} \ar[r] & c[n]}    
%   \end{tabular}
%   \caption{Computation of Mel-frequency cepstrum coefficients}
%   \label{fig:mfcc}
% \end{figure}
% 
% % subsection Mel-Frequency Cepstrum (end)
% chapter Theory (end)